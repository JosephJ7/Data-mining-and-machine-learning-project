{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6323c379",
   "metadata": {},
   "source": [
    "# 1. Introduction and Dataset Overview\n",
    "\n",
    "\n",
    "Dataset Name: Real or Fake Job Posting Prediction\n",
    "\n",
    "Source: Kaggle (https://www.kaggle.com/datasets/shivamb/real-or-fake-fake-jobposting-prediction/data)\n",
    "\n",
    "Purpose: To predict whether a job posting is real or fake.\n",
    "\n",
    "Problem Type: Binary Classification\n",
    "\n",
    "Target Variable: fraudulent (1: Fake, 0: Real)\n",
    "\n",
    "Key Features: title, company_profile, description, requirements, benefits, employment_type, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed67a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import zscore\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7ff798",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Download stopwords if not already downloaded\n",
    "try:\n",
    "    stopwords.words('english')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f396113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv(\"fake_job_postings.csv\")  # Load from local file\n",
    "except FileNotFoundError:\n",
    "    # If the file is not found locally, attempt to load it from the Kaggle URL.  This will likely fail.\n",
    "    print(\"Error: 'fake_job_postings.csv' not found. Please download it from Kaggle and place it in the same directory as this script.\")\n",
    "    df = None # set df to None to prevent further errors\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50561aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for balanced or imbalanced class distribution\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(df['fraudulent'].value_counts())\n",
    "print(f\"\\nProportion of Fake Postings: {df['fraudulent'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a02ab3",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca70656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2735bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unwanted columns\n",
    "unwanted_columns = ['job_id']  # Removed location - high cardinality, difficult to process\n",
    "df = df.drop(columns=unwanted_columns, errors='ignore')\n",
    "print(\"\\nAfter Dropping Unwanted Columns:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48278b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Missing Data\n",
    "print(\"\\nMissing Data Before Handling:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e36fd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing text data with \"Missing\"\n",
    "text_columns = ['title', 'company_profile', 'description', 'requirements', 'benefits']\n",
    "df[text_columns] = df[text_columns].fillna('Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ce9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute categorical features with the mode\n",
    "categorical_columns = ['employment_type', 'required_education', 'required_experience', 'functional_area', 'industry']\n",
    "for col in categorical_columns:\n",
    "    mode_val = df[col].mode()[0]\n",
    "    df[col] = df[col].fillna(mode_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196146cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute numerical features (if any) with the median (if any numerical columns exist)\n",
    "numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "numerical_cols.remove('fraudulent') # remove the target variable\n",
    "if numerical_cols: # Check if there are any numerical columns\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    df[numerical_cols] = imputer.fit_transform(df[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550bef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing Data After Handling:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1391cc",
   "metadata": {},
   "source": [
    "## Feature Engineering & Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead6a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans the input text by removing punctuation, converting to lowercase,\n",
    "    and removing stop words.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned text.\n",
    "    \"\"\"\n",
    "    if isinstance(text, str):  # Check if the input is a string\n",
    "        text = text.lower()\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = text.split()\n",
    "        tokens = [w for w in tokens if not w in stop_words]\n",
    "        return \" \".join(tokens)\n",
    "    else:\n",
    "        return \"\" # Return empty string for non-string input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af0f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning function to the text columns\n",
    "for col in text_columns:\n",
    "    df[col] = df[col].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c6db2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all text columns into a single text feature\n",
    "df['combined_text'] = df[text_columns].apply(lambda row: ' '.join(row.values), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1a0823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the combined text using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)  # Limiting features can improve performance\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['combined_text'])\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a50ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate TF-IDF features with the original dataframe\n",
    "df = pd.concat([df, tfidf_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1531d13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original text columns and the combined text column\n",
    "df = df.drop(columns=text_columns + ['combined_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883fde71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nData After Text Vectorization:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e504a76",
   "metadata": {},
   "source": [
    "## Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e77681",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nOutlier Detection and Removal (Z-score):\")\n",
    "numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "numerical_cols.remove('fraudulent') # Remove target\n",
    "if numerical_cols:\n",
    "    df_no_target = df[numerical_cols]\n",
    "    z_scores = zscore(df_no_target)\n",
    "    abs_z_scores = np.abs(z_scores)\n",
    "    filtering_mask = (abs_z_scores < 3).all(axis=1) # boolean mask of rows with z-score < 3 for all cols\n",
    "    df = df[filtering_mask] # Apply the mask\n",
    "    print(f\"Shape after outlier removal: {df.shape}\")\n",
    "else:\n",
    "    print(\"No numerical columns for outlier detection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4137ae8",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72d650e",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da99966",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70589129",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d8cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(include=np.number)\n",
    "correlation_matrix = numeric_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079d9fb4",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013ec53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm')  # Removed annot=True for better visualization\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef47c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='fraudulent', data=df)\n",
    "plt.title('Distribution of Target Variable (Fraudulent)')\n",
    "plt.xlabel('Fraudulent (0: Real, 1: Fake)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bdc51d",
   "metadata": {},
   "source": [
    "# 4. Model Selection and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087b32b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['fraudulent'])\n",
    "y = df['fraudulent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa274c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.5, stratify=y, random_state=42) # 50% train\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.4, stratify=y_temp, random_state=42) # 30% val, 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83f7498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold cross-validation (Stratified)\n",
    "def perform_cross_validation(model, X, y, cv=5):\n",
    "    \"\"\"\n",
    "    Performs stratified k-fold cross-validation and returns the mean and standard deviation\n",
    "    of the F1-score.\n",
    "\n",
    "    Args:\n",
    "        model: The machine learning model to evaluate.\n",
    "        X (pd.DataFrame): The feature matrix.\n",
    "        y (pd.Series): The target variable.\n",
    "        cv (int): The number of folds for cross-validation.  Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (mean_f1, std_f1) - The mean and standard deviation of the F1-score.\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42) # Use StratifiedKFold\n",
    "    f1_scores = cross_val_score(model, X, y, cv=skf, scoring='f1')\n",
    "    return np.mean(f1_scores), np.std(f1_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae732cc",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dec4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model = LogisticRegression(random_state=42, solver='liblinear', class_weight='balanced') # Add class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab674b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCross-Validation Results:\")\n",
    "lr_mean_f1, lr_std_f1 = perform_cross_validation(logistic_regression_model, X_train, y_train)\n",
    "print(f\"Logistic Regression: Mean F1-score = {lr_mean_f1:.4f}, Std F1-score = {lr_std_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc79aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70ac6a6",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7415a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model = RandomForestClassifier(random_state=42, class_weight='balanced') # Add class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8df0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCross-Validation Results:\")\n",
    "rf_mean_f1, rf_std_f1 = perform_cross_validation(random_forest_model, X_train, y_train)\n",
    "print(f\"Random Forest: Mean F1-score = {rf_mean_f1:.4f}, Std F1-score = {rf_std_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dea8bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4b2eff",
   "metadata": {},
   "source": [
    "# 5. Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317a7056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Evaluates the performance of a given model and prints various metrics.\n",
    "    Also generates and displays the confusion matrix and ROC curve.\n",
    "\n",
    "    Args:\n",
    "        model: The trained machine learning model.\n",
    "        X (pd.DataFrame): The feature matrix.\n",
    "        y (pd.Series): The target variable.\n",
    "        model_name (str): Name of the model\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    roc_auc = roc_auc_score(y, y_pred_proba)\n",
    "\n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    confusion_matrix_display = ConfusionMatrixDisplay(confusion_matrix(y, y_pred), display_labels=[0, 1])\n",
    "    confusion_matrix_display.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y, y_pred_proba)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'{model_name} ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Precision-Recall Curve\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(y, y_pred_proba)\n",
    "    average_precision = average_precision_score(y, y_pred_proba)\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(recall_curve, precision_curve, color='b',\n",
    "             label=f'{model_name} (AP = {average_precision:.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'{model_name} Precision-Recall Curve')\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.show()\n",
    "    return y_pred, y_pred_proba #returning the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5209e4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Logistic Regression\n",
    "y_pred_lr, y_pred_proba_lr = evaluate_model(logistic_regression_model, X_test, y_test, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb21598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Random Forest\n",
    "y_pred_rf, y_pred_proba_rf = evaluate_model(random_forest_model, X_test, y_test, \"Random Forest\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
